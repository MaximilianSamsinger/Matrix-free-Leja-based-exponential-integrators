\documentclass{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[ngerman,english]{babel}
\usepackage{blindtext}
\usepackage{color}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{subcaption}
\usepackage{upgreek}
\usepackage{amsmath,amssymb,amsthm,mathtools}
\usepackage{multirow}
\usepackage{float}


\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\defneq}{\mathrel{\mathop:}=}
\newcommand{\eqdefn}{=\mathrel{\mathop:}}

%\newcommand{\myparagraph}[1]{\paragraph{#1}\mbox{}\}
%\setlength{\parindent}{0em}

\begin{document}


\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{bsp}{Beispiel}[section]
\newtheorem{satz}{Satz}[section]
\newtheorem{prop}{Proposition}
\newtheorem{lem}[satz]{Lemma}
\newtheorem*{bem}{Bemerkung}
\newtheorem*{rem}{Remark}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%


%\title{The Leja method in Python}
%\subtitle{supervised by Peter Kandolf, Alexander Ostermann}
%\maketitle
%\author{Maximilian Samsinger}
\begin{titlepage}
\noindent\makebox[\textwidth][c]{\includegraphics[width=\paperwidth]{leiste.png}}
\vspace{3cm}
\begin{center}
{\Large Master Thesis}
\vspace{50pt}\\
\textbf{\Huge Matrix-free Leja based exponential integrators in Python}
\vspace{40pt}\\
\textbf{\Large Maximilian Samsinger}\vspace{20pt}\\
{\large\today}
\vspace{120pt}\\
{\Large Supervised by Lukas Einkemmer and\\
Alexander Ostermann\vspace{10pt}}
\end{center}
\end{titlepage}
\textsf{
{\hspace{-16pt}\large\textbf{Leopold-Franzens-Universität Innsbruck}}
\begin{figure}[!htp]
\begin{flushright}
	\includegraphics[scale=0.1]{./uni_logo}
\end{flushright}
\end{figure}\\\\
{\Large\textbf{Eidesstattliche Erklärung}}\\\\
Ich erkläre hiermit an Eides statt durch meine eigenhändige Unterschrift, dass ich die\\ vorliegende Arbeit selbständig verfasst und keine anderen als die angegebenen Quellen und\\ Hilfsmittel verwendet habe. Alle Stellen, die wörtlich oder inhaltlich den angegebenen Quellen \\entnommen wurden, sind als solche kenntlich gemacht.\\\\
Ich erkläre mich mit der Archivierung der vorliegenden Bachelorarbeit einverstanden.
\vspace{40pt}\\
\begin{center}
\ensuremath{\overline{\mbox{Datum}\hspace{8em}}
    \hspace{10em}
    \overline{\mbox{Unterschrift}\hspace{10em}}
}
\thispagestyle{empty}
\end{center}}
\pagebreak



\begin{center}\textbf{\Huge Matrix-free Leja based exponential integrators in Python}\end{center}
\begin{center}\textbf{Abstract}\end{center}
\begin{abstract}

\end{abstract}

\setcounter{page}{1}

\section{Introduction}
%%%%%%%%
%Examples needed
%%%%%%%%%%
Consider the action of the matrix exponential function 
	\[e^Av,\quad A\in\mathbb{C}^{N\times N}, v\in\mathbb{C}^N.\] 
It can be difficult or impossible to compute $e^A$ in a first step and then the action $e^Av$ in a seperate step. This is especially true in applications where $N>10000$ is not uncommon. Furthermore the matrix exponential of a sparse matrix is in general no longer sparse. Therefore it is more feasable to compute the action of the matrix exponential in a single step. This can be done by approximating the matrix exponential with a matrix polynomial $p_n$ of degree $n$ in $A$
	\[e^Av \approx p_n(A)v.\]
This approach has many advantages. The cost of the computation of $p_n(A)v$ mainly depends on the calculation of $n$ matrix-vector multiplications with $A$. Furthermore the explicit knowledge of $A$ itself is no longer required. $A$ can be replaced by a linear function, which can be more convenient and saves memory.

\section{The Leja method}
In this section we explore the core concepts of the Leja method for the exponential function. This serves as an introduction for the 

\paragraph{Replacing the matrix exponential with a polynomial:}

\paragraph{Exploiting the properties of the matrix exponential functions:}

\paragraph{Evaluate the polynomial using precomputed Leja interpolation nodes:}

\section{Linear advection diffusion equation}

\paragraph{Plot the eigenvalues of the matrix}


\section{Numerical experiments}
For the first experiments we will discretize multiple one-dimensional advection-diffusion-reaction equations with hybrid difference schemes.\footnote{Need a source, https://en.wikipedia.org/wiki/Hybrid\_difference\_scheme} We will always choose an equidistant grid with grid size $h = \frac{1}{N}$, $N\in\mathbb{N}$ and grid points $x_i = ih$ for $i=0\dots,N$ on the domain $\Omega = [0,1]$. The resulting ordinary differential equations (ODEs) will be solved with four different integrators. Our goal is to investigate the respective computational costs of these methods while achieving a prescribed relative tolerance \texttt{tol}.

\paragraph{Crank-Nicolson method:}
	We refer to the Crank-Nicolson method of order 2 as \texttt{cn2}. 
	In our implementation of \texttt{cn2}, we used the SciPy\cite{scipy} package \texttt{scipy.sparse.linalg.gmres} to solve linear equations. We set the relative tolerance to $\texttt{tol}/s$, where $s$ is the total number of substeps taken for solving the ODE. This choice guarantees that the sum of errors made by \texttt{gmres} is always lower than our specified tolerance \texttt{tol}, since we have to solve exactly one linear equation per substep. No preconditioner was used for \texttt{gmres}. The Crank-Nicolson method is unconditionally stable and therefore does not have to satisfy the Courant-Friedrichs-Lewy (CFL) conditions imposed by the advective and diffusive part of the differential equations.
	
\paragraph{Exponential Rosenbrock-Euler method:}
	We refer to the Exponential Rosenbrock-Euler method of order 2 as \texttt{exprb2}.
	The approximate the action of the matrix exponential with the Leja method. No hump reduction is used. The maximal interpolation degree is set to 100. Note that the total number of matrix-vector multiplication per time step can still exeed 100 since we have to compute a single matrix norm. This typically happens for $s=1$. 

\paragraph{Explicit midpoint method:}
	We refer to the explicit midpoint method of order 2 as \texttt{rk2}. 

\paragraph{Classical Runge kutta:}
	We refer to the classical Runge-Kutta method of order 4 as \texttt{rk4}.\\


\noindent For our experiments we will often fix one of two different P\'eclet numbers
\[\texttt{Pe} = \frac{b}{a}, \quad \texttt{pe} = \frac{hb}{2a},\]
The P\'eclet numbers are dimensionless quantities representing the ratio of the advective velocity $b$ to the diffusive velocity $a$. While \texttt{Pe} characterizes the original partial differential equation, the grid P\'eclet number \texttt{pe} is the dimensionless quantity for the resulting ODE after discretization. Note that by fixing \texttt{pe} for varying grid sizes, we have to change the original partial differential equantion. Unless otherwise noted we accomplish that by replacing $b$ with $2b$ and $a$ with $ah$.
   

\subsection{Experiment 1: Linear advection diffusion equation}
Consider the one-dimensional advection-diffusion equation
\begin{align*}
\partial_tu &= a\partial_{xx}u + b\partial_xu \quad a,b\ge 0\\
u_0(t) &= e^{-80\cdot(t-0,45)^2} \quad t\in[0,0.1]
\end{align*}
with homogeneous Dirichlet boundary conditions on the domain $\Omega = [0,1]$. 
For a fixed $N\in\mathbb N$ we approximate the diffusive part with second-order central differences on an equidistant grid with grid size $h = \frac{1}{N}$ and grid points $x_i = ih$, $i=0\dots,N$.
\[\partial_{xx}u(x_i) = \frac{u(x_{i+1}) - 2u(x_i) + u(x_{i-1})}{{h}^2} + \mathcal{O}({h}^2)\]
In order to limit numerical instabilities we discretize the advective part with forward differences, similar to the upwind scheme.\footnote{Maybe create a seperate section on hybrid difference schemes? There we can also analyze the resulting matrix $A$ itself and plot the eigenvalues. I need sources for that though.}
\[\partial_{x}u(x_i) = \frac{u(x_{i+1}) - u(x_i)}{h} + \mathcal{O}(h)\]
The resulting system of ordinary differential equation is given by
\begin{align*}
\partial_tu &= Au.
\end{align*} 
Some eigenvalues of $A$ can have an extremely large negative real part. Therefore, since no explicit Runge-Kutta method is A-stable, this imposes very stingend conditions on the time step size $\uptau$ for $\operatorname{rk2}$ and $\operatorname{rk4}$.\footnote{See section \ref{CFL}} We will refer to the Courant-Friedrich-Lewy (CFL) conditions imposed by the advective and diffusive part of $A$ respectively by $C_{adv}$ and $C_{dif}$.  
\[ C_{adv} = \frac{b\uptau}{h} \le 1, \quad C_{dif} = \frac{a\uptau}{h^2} \le \frac{1}{2}\] 



In our case the problem is fully linear and therefore $\texttt{exprb2}$ simplifies to the computation of the action of the matrix exponential funcion with the Leja method. We write $\texttt{expleja}$ for the single precision Leja method approximation. Note that reference solution was computed with double precision and therefore uses different nodes.

In order to keep the solution from vanishing, we fix $b = 1$ and only consider coefficients $a\in[0,1]$. The advection-diffusion ratio scaled by the grid size $h$ is represented by the grid P\'eclet number


\section{Appendix}
%
%\subsection{CFL Condition} \label{CFL}
%We conduct a Von Neumann stability analysis for the diffusion equation
%\[ \partial_tu = \partial_{xx}u. \]
%The eigenfunctions of $\partial_{xx}$ are given by
%\[ u_k(x) = e^{ikx} \]
%with eigenvalues $-k^2$.

\subsection{Experiment 1}
\newcommand{\Pe}{Pe=1.0}
\newcommand{\precision}{single}
\newcommand{\safe}{sf=1.0}

\begin{figure}[H]
	\centering
	\includegraphics[]{../figures/Experiment1/{1, \precision, \Pe}.pdf}
%	\caption{Remark: In this case $N$ is equal to the grid P\'eclet number $\operatorname{pe}$.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[]{../figures/Experiment1/{2, \precision, \Pe}.pdf}
%	\caption{A picture of a gull.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[]{../figures/Experiment1/{3, \precision, \Pe}.pdf}
%	\caption{A picture of a gull.}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[]{../figures/Experiment1/{4, \precision}.pdf}
%	\caption{A picture of a gull.}
\end{figure}

\subsection{Experiment 1.5}
In the matrix-free case the linear operator $A$ is not explicitly given. In order to compute the matrix norm ${\norm A}_2$ we use power iterations to estimate the absolutely largest eigenvalue of $A$. A priory it is not clear how many power iterations $it$ are neccessary for a good approximation. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=1.\columnwidth]{../figures/Experiment1LinOp/{1, \precision, \Pe, \safe}.pdf}
	\caption{Space dimension $N$ vs costs \texttt{mv} per timestep \texttt{s} for the exponential Rosenbrock method \texttt{exprb2}. Results are only shown if they achieve \precision\ precision.}
\end{figure}


%DESCRIPTION OF THE EXPERIMENT, NUMBER OF POWERITS, SAFETYFACTOR, HOW STABLE IS THE COMPUTATION???
%First that the matrix $A = A(t)$ changes at every time step and therefore




\clearpage
\begin{thebibliography}{6}
	\bibitem{rosenbr} M. Caliari, A. Ostermann. Implementation of exponential Rosenbrock-type integrators, Applied Numerical Mathematics 59 (2009), 568-581.
	\bibitem{action} A. Al-Mohy, N. Higham. Computing the action of the matrix exponential, with an application to exponential integrators, SIAM Journal on Scientific Computing 33 (2011), 488-511.
	\bibitem{newt} L. Reichel. Newton interpolation at Leja points, BIT Numerical Mathematics 30 (1990), 332-346.
    \bibitem{advdif} M. Caliari, M. Vianello, L. Bergamaschi. Interpolating discrete advection-diffusion propagators at Leja sequences, Journal of Computational and Applied Mathematics 172 (2004), 79-99.
    \bibitem{lejarev} M. Caliari, P. Kandolf, A. Ostermann, S. Rainer. The Leja method revisited: backward error analysis for the matrix exponential, SIAM Journal on Scientific Computation, Accepted for publication (2016). arXiv:1506.08665.
    \bibitem{python} Python Software Foundation. Python Language Reference, version 2.7. Available at http://www.python.org. Manual at https://docs.python.org/2/. [Online; accessed 2015-12-14]
    %\bibitem{numpy} S. v. d. Walt, C. Colbert, G Varoquaux, The NumPy Array: A Structure for Efficient Numerical Computation, Computing in Science & Engineering, 13, 22-30 (2011)
    \bibitem{scipy} E. Jones, E. Oliphant, P. Peterson, SciPy: Open Source Scientific Tools for Python, Available at http://www.scipy.org/. [Online; accessed 2015-12-14]
\end{thebibliography}


\end{document}
